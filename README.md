# ğŸŒ¾ SystÃ¨me d'Extraction de Connaissances de Plantes Agricoles

SystÃ¨me d'extraction automatique de connaissances Ã  partir d'images de plantes agricoles du Burkina Faso (maÃ¯s, oignon, tomate). Combine des LLM locaux via Ollama (LLaVA 13b) et une ontologie de domaine pour produire un schÃ©ma structurÃ© Data Vault.

## ğŸ“‹ Table des matiÃ¨res

- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Architecture](#-architecture)
- [PrÃ©requis](#-prÃ©requis)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Pipeline d'extraction](#-pipeline-dextraction)
- [Structure du projet](#-structure-du-projet)
- [Configuration](#-configuration)
- [API](#-api)
- [DÃ©pannage](#-dÃ©pannage)

## âœ¨ FonctionnalitÃ©s

- **Analyse d'images** de plantes avec LLaVA (vision + langage)
- **Extraction automatique** de lemmes descriptifs
- **Classification ontologique** guidÃ©e (Hubs, Links, Satellites)
- **Calcul de similaritÃ©** hybride (lexicale + sÃ©mantique)
- **SchÃ©ma Data Vault** structurÃ© et validÃ©
- **Exports multi-formats** : JSON, RDF/Turtle, SQL
- **Interface Gradio** interactive et intuitive
- **ExÃ©cution locale** avec Docker et Ollama

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Image de       â”‚
â”‚  plante         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰TAPE 1: Extraction LLM (LLaVA)     â”‚
â”‚ Lemmes: [mais, malade, necrose, ...] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰TAPE 2: Classification Ontologique â”‚
â”‚ RÃˆGLE 1: Hubs (EntitÃ©s)             â”‚
â”‚ RÃˆGLE 2: Links (Relations)          â”‚
â”‚ RÃˆGLE 3: Satellites (Attributs)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰TAPE 3: Calcul de SimilaritÃ©       â”‚
â”‚ - Lexicale (Jaro-Winkler)           â”‚
â”‚ - SÃ©mantique (Embeddings)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰TAPE 4: SchÃ©ma Data Vault          â”‚
â”‚ - Hubs, Links, Satellites           â”‚
â”‚ - Validation, MÃ©tadonnÃ©es           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
   â”‚ Exports â”‚
   â””â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”˜
     â”‚   â”‚   â”‚
   JSON RDF SQL
```

## ğŸ“¦ PrÃ©requis

- **Docker** et **Docker Compose** (recommandÃ©)
- **Python 3.11** (si installation locale)
- **4-10 GB RAM** (selon le modÃ¨le choisi: 4GB pour llava:7b, 10GB pour llava:13b)
- **GPU NVIDIA** (optionnel, pour accÃ©lÃ©ration)

## ğŸš€ Installation

### Option 1: Docker (RecommandÃ©)

```bash
# 1. Cloner le repository
git clone <votre-repo>
cd LemmesExtraction

# 2. Copier et adapter le fichier d'environnement
cp .env.example .env

# 3. Lancer les services
docker-compose up --build -d

# 4. TÃ©lÃ©charger les modÃ¨les LLM (premiÃ¨re utilisation)
# Choisissez selon votre RAM disponible:
docker-compose exec ollama ollama pull llava:7b          # RecommandÃ©: 4-5 GB RAM
docker-compose exec ollama ollama pull qwen2.5vl:latest  # Moderne: 6 GB RAM
docker-compose exec ollama ollama pull llama3.2-vision:latest  # Optionnel: 7-8 GB RAM
docker-compose exec ollama ollama pull llava:13b         # Optionnel: 10 GB RAM (âš ï¸ Haute RAM)

# 5. VÃ©rifier les logs
docker-compose logs -f app
```

L'interface Gradio sera accessible sur **http://localhost:7860**

### Option 2: Installation locale

```bash
# 1. CrÃ©er un environnement virtuel Python 3.11
python3.11 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 2. Installer les dÃ©pendances
pip install -r requirements.txt

# 3. Installer Ollama sÃ©parÃ©ment
# https://ollama.com/download

# 4. TÃ©lÃ©charger les modÃ¨les LLM (au choix)
ollama pull llava:7b          # RecommandÃ©: 4-5 GB RAM
ollama pull qwen2.5vl:latest  # Moderne: 6 GB RAM
ollama pull llama3.2-vision:latest  # Optionnel: 7-8 GB RAM
ollama pull llava:13b         # Optionnel: 10 GB RAM (âš ï¸ Haute RAM)

# 5. Copier et adapter la configuration
cp .env.example .env
# Ã‰diter .env pour mettre OLLAMA_BASE_URL=http://localhost:11434

# 6. Lancer Ollama (dans un terminal sÃ©parÃ©)
ollama serve

# 7. Lancer l'application
python src/app.py
```

## ğŸ’» Utilisation

### Interface Gradio

1. **Ouvrir** http://localhost:7860
2. **Onglet "Analyse d'Image"** :
   - Uploader une image de plante
   - Choisir le modÃ¨le LLM (llava:7b, qwen2.5vl, llama3.2-vision, ou llava:13b)
   - Ajuster les seuils de similaritÃ© (optionnel)
   - Cliquer sur "Analyser"
   - Visualiser les rÃ©sultats (Hubs, Links, Satellites)
3. **Onglet "Export"** :
   - Choisir le format (JSON, RDF, SQL)
   - Cliquer sur "Exporter"
   - TÃ©lÃ©charger le fichier gÃ©nÃ©rÃ©
4. **Onglet "Ontologie"** :
   - Consulter les statistiques de l'ontologie

### Commandes Docker utiles

```bash
# Voir les logs
docker-compose logs -f app
docker-compose logs -f ollama

# RedÃ©marrer les services
docker-compose restart

# ArrÃªter les services
docker-compose down

# Reconstruire aprÃ¨s modification du code
docker-compose up --build -d

# VÃ©rifier les modÃ¨les Ollama disponibles
docker-compose exec ollama ollama list
```

## ğŸ”„ Pipeline d'extraction

### Ã‰TAPE 1: Extraction de lemmes (LLaVA)

```python
# EntrÃ©e: Image de plante
# Sortie: Liste de lemmes
lemmes = ["mais", "malade", "helminthosporiose", "necrose",
          "vert_moyen", "beige_brun", "lineaire_lanceolee"]
```

### Ã‰TAPE 2: Classification ontologique

**RÃˆGLE 1: Hubs (EntitÃ©s)**
- Seuil: Î¸e = 0.75
- DÃ©tecte: plantes, maladies, symptÃ´mes
- Exemple: "mais" â†’ Hub(type=plante), "helminthosporiose" â†’ Hub(type=maladie)

**RÃˆGLE 2: Links (Relations)**
- Seuil: Î¸r = 0.70
- DÃ©tecte: relations entre entitÃ©s
- Exemple: Link(mais â†’ a_maladie â†’ helminthosporiose)

**RÃˆGLE 3: Satellites (Attributs)**
- Seuil: Î¸a = 0.65
- DÃ©tecte: attributs descriptifs
- Exemple: Satellite(hub=mais, attribut=couleur_feuille, valeur=vert_moyen)

### Ã‰TAPE 3: Calcul de similaritÃ©

```python
sim(lemme, concept) = max(sim_lex, sim_sem)

# SimilaritÃ© lexicale (Jaro-Winkler)
sim_lex("mais", "maÃ¯s") = 1.0

# SimilaritÃ© sÃ©mantique (Embeddings)
sim_sem("jaunissement", "chlorose") = 0.82
```

### Ã‰TAPE 4: SchÃ©ma Data Vault

```json
{
  "hubs": [
    {
      "hub_key": "abc123...",
      "business_key": "mais",
      "entity_type": "plante",
      "confidence_score": 0.98
    }
  ],
  "links": [...],
  "satellites": [...]
}
```

## ğŸ“ Structure du projet

```
LemmesExtraction/
â”œâ”€â”€ docker-compose.yml          # Orchestration Docker
â”œâ”€â”€ Dockerfile                  # Image Python
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ .env.example               # Template de configuration
â”œâ”€â”€ README.md                  # Documentation
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/                # Images d'entrÃ©e
â”‚   â”‚   â”œâ”€â”€ img1.jpg          # MaÃ¯s sain
â”‚   â”‚   â”œâ”€â”€ img2.jpg          # Tomate avec acariens
â”‚   â”‚   â”œâ”€â”€ img3.jpg          # MaÃ¯s avec chenille
â”‚   â”‚   â””â”€â”€ img4.jpg          # MaÃ¯s avec helminthosporiose
â”‚   â””â”€â”€ ontology/
â”‚       â””â”€â”€ ontologie_plantes_burkina_faso.ttl  # Ontologie RDF
â”œâ”€â”€ exports/                   # Fichiers exportÃ©s (gÃ©nÃ©rÃ©)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ app.py                 # Interface Gradio (point d'entrÃ©e)
â”‚   â”œâ”€â”€ llm_extractor.py       # Extraction LLaVA
â”‚   â”œâ”€â”€ ontology_loader.py     # Chargement ontologie RDF
â”‚   â”œâ”€â”€ similarity_calculator.py # Calcul similaritÃ©
â”‚   â”œâ”€â”€ ontology_matcher.py    # Classification (3 rÃ¨gles)
â”‚   â”œâ”€â”€ datavault_generator.py # GÃ©nÃ©ration schÃ©ma Data Vault
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ hub.py             # ModÃ¨le Hub
â”‚   â”‚   â”œâ”€â”€ link.py            # ModÃ¨le Link
â”‚   â”‚   â””â”€â”€ satellite.py       # ModÃ¨le Satellite
â”‚   â””â”€â”€ exporters/
â”‚       â”œâ”€â”€ json_exporter.py   # Export JSON
â”‚       â”œâ”€â”€ rdf_exporter.py    # Export RDF/Turtle
â”‚       â””â”€â”€ sql_exporter.py    # Export SQL
â””â”€â”€ tests/
    â””â”€â”€ test_pipeline.py       # Tests d'intÃ©gration
```

## âš™ï¸ Configuration

### Variables d'environnement (.env)

```bash
# Ollama
OLLAMA_BASE_URL=http://ollama:11434
LLAVA_MODEL=llava:13b

# Chemins
ONTOLOGY_PATH=data/ontology/ontologie_plantes_burkina_faso.ttl
IMAGES_PATH=data/images/
EXPORT_PATH=exports/

# Seuils de similaritÃ©
THRESHOLD_ENTITIES=0.75    # Seuil pour Hubs
THRESHOLD_RELATIONS=0.70   # Seuil pour Links
THRESHOLD_ATTRIBUTES=0.65  # Seuil pour Satellites

# Gradio
GRADIO_SERVER_PORT=7860
GRADIO_SERVER_NAME=0.0.0.0

# Embeddings
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2
```

### Ajustement des seuils

- **Seuils Ã©levÃ©s (0.8-1.0)** : PrÃ©cision maximale, peut manquer des correspondances
- **Seuils moyens (0.65-0.75)** : Bon Ã©quilibre (recommandÃ©)
- **Seuils faibles (0.5-0.65)** : Capture plus de correspondances, moins prÃ©cis

Les seuils peuvent Ãªtre ajustÃ©s dynamiquement via l'interface Gradio.

## ğŸ”Œ API

### Utilisation programmatique

```python
from src.ontology_loader import OntologyLoader
from src.llm_extractor import LLMExtractor
from src.similarity_calculator import SimilarityCalculator
from src.ontology_matcher import OntologyMatcher
from src.datavault_generator import DataVaultGenerator

# 1. Charger l'ontologie
ontology = OntologyLoader("data/ontology/ontologie_plantes_burkina_faso.ttl")

# 2. Initialiser les composants
llm_extractor = LLMExtractor("http://localhost:11434", "llava:13b")
similarity_calc = SimilarityCalculator()
matcher = OntologyMatcher(ontology, similarity_calc, {
   "entities": 0.75,
   "relations": 0.70,
   "attributes": 0.65
})

# 3. Analyser une image
lemmas = llm_extractor.extract_lemmas("data/images/img1.jpg")
hubs, links, satellites = matcher.classify_lemmas(lemmas, "img1.jpg")

# 4. GÃ©nÃ©rer le schÃ©ma
generator = DataVaultGenerator()
schema = generator.generate_schema(hubs, links, satellites, "img1.jpg", lemmas)

# 5. Exporter
from src.exporters.json_exporter import JSONExporter

exporter = JSONExporter()
exporter.export(schema, "exports/schema.json")
```

## ğŸ› DÃ©pannage

### Erreur: Ollama non disponible

```bash
# VÃ©rifier que le service Ollama est lancÃ©
docker-compose ps ollama

# VÃ©rifier les logs
docker-compose logs ollama

# RedÃ©marrer Ollama
docker-compose restart ollama
```

### Erreur: ModÃ¨le LLaVA introuvable

```bash
# TÃ©lÃ©charger le modÃ¨le
docker-compose exec ollama ollama pull llava:13b

# VÃ©rifier les modÃ¨les disponibles
docker-compose exec ollama ollama list
```

### Erreur: Out of memory

- **RÃ©duire la taille du modÃ¨le** : Dans l'interface, sÃ©lectionner `llava:7b` (4GB) au lieu de `llava:13b` (10GB)
- **Augmenter la mÃ©moire Docker** : Dans Docker Desktop, augmenter la RAM allouÃ©e
- **Utiliser un GPU** : DÃ©commenter les sections GPU dans docker-compose.yml (Linux/WSL2 + NVIDIA)

### Comparaison des modÃ¨les

| ModÃ¨le | RAM requise | Vitesse | PrÃ©cision | Usage recommandÃ© |
|--------|-------------|---------|-----------|------------------|
| llava:7b | 4-5 GB | Rapide | Bonne | Tests, machines limitÃ©es |
| qwen2.5vl:latest | 6 GB | TrÃ¨s rapide | TrÃ¨s bonne | Moderne, multilingue performant â­ |
| llama3.2-vision | 7-8 GB | Rapide | TrÃ¨s bonne | Usage gÃ©nÃ©ral, Ã©quilibrÃ© |
| llava:13b | 10 GB | Moyen | Excellente | Production, prÃ©cision max (âš ï¸ RAM Ã©levÃ©e) |

### Erreur: Ontologie introuvable

```bash
# VÃ©rifier que le fichier existe
ls data/ontology/ontologie_plantes_burkina_faso.ttl

# VÃ©rifier les chemins dans .env
cat .env | grep ONTOLOGY_PATH
```

### Interface Gradio ne se charge pas

```bash
# VÃ©rifier les logs de l'application
docker-compose logs app

# VÃ©rifier que le port 7860 n'est pas dÃ©jÃ  utilisÃ©
netstat -an | grep 7860  # Linux/Mac
netstat -an | findstr 7860  # Windows

# RedÃ©marrer l'application
docker-compose restart app
```

## ğŸ“Š Exemples de rÃ©sultats

### Exemple 1: MaÃ¯s sain (img1.jpg)

**Lemmes extraits:**
```
mais, sain, vert_fonce, lineaire_lanceolee, nervation_parallele, lisse
```

**Hubs:**
- `mais` (plante, score: 1.0)

**Satellites:**
- `couleur_feuille` = vert_fonce (score: 0.92)
- `forme_feuille` = lineaire_lanceolee (score: 0.98)
- `nervation` = nervation_parallele (score: 0.95)

### Exemple 2: MaÃ¯s avec helminthosporiose (img4.jpg)

**Lemmes extraits:**
```
mais, malade, helminthosporiose, necrose, vert_moyen, beige_brun
```

**Hubs:**
- `mais` (plante, score: 1.0)
- `helminthosporiose` (maladie, score: 0.96)
- `necrose` (symptome, score: 0.89)

**Links:**
- `mais` â†’ `a_maladie_mais` â†’ `helminthosporiose` (score: 0.85)
- `mais` â†’ `presente_symptome` â†’ `necrose` (score: 0.80)
- `helminthosporiose` â†’ `cause_symptome` â†’ `necrose` (score: 0.75)

**Satellites:**
- `couleur_feuille` = vert_moyen (score: 0.88)
- `couleur_feuille` = beige_brun (score: 0.91)

## ğŸ”¬ Technologies

- **LLM/Vision:** Ollama (LLaVA 7b/13b, Qwen 2.5 Vision, Llama 3.2 Vision)
- **Ontologie:** RDFLib, OWL/RDF
- **SimilaritÃ©:** Jellyfish (Jaro-Winkler), Sentence-Transformers
- **Interface:** Gradio
- **Containerisation:** Docker, Docker Compose
- **Langage:** Python 3.11

## ğŸ“ License

MIT License

## ğŸ‘¥ Contributeurs

DÃ©veloppÃ© pour l'analyse de plantes agricoles du Burkina Faso.

## ğŸ“§ Contact

Pour toute question ou contribution, ouvrir une issue sur le repository.

---

**Version:** 1.0.0
**DerniÃ¨re mise Ã  jour:** 2026-01-07
